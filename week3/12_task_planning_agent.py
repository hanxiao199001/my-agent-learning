"""
ä»»åŠ¡è§„åˆ’ Agent - è‡ªåŠ¨åˆ†è§£å¤æ‚ä»»åŠ¡
å­¦ä¹ ç›®æ ‡:è®© AI å­¦ä¼šæŠŠå¤§ä»»åŠ¡æ‹†æˆå°ä»»åŠ¡å¹¶é€æ­¥æ‰§è¡Œ
"""

import os
import json
from openai import OpenAI
from dotenv import load_dotenv
from tavily import TavilyClient

load_dotenv()

openai_client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com"
)

tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))

# ========== å·¥å…·å‡½æ•° ==========

def web_search(query):
    """ç½‘ç»œæœç´¢"""
    try:
        response = tavily_client.search(query=query, max_results=3, include_answer=True)
        
        # æå–ç­”æ¡ˆå’Œç»“æœ
        answer = response.get('answer', '')
        results = [
            f"æ¥æº: {r['title']}\nå†…å®¹: {r['content'][:200]}"
            for r in response.get('results', [])[:2]
        ]
        
        output = f"AIæ€»ç»“: {answer}\n\nè¯¦ç»†ä¿¡æ¯:\n" + "\n\n".join(results)
        return output
    except Exception as e:
        return f"æœç´¢å¤±è´¥: {str(e)}"

def calculate(expression):
    """æ•°å­¦è®¡ç®—"""
    try:
        expression = expression.replace('^', '**')
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"

# ========== ä»»åŠ¡è§„åˆ’ Agent ==========

def planning_agent(task):
    """
    ä»»åŠ¡è§„åˆ’ Agent
    1. åˆ†æä»»åŠ¡å¤æ‚åº¦
    2. åˆ¶å®šæ‰§è¡Œè®¡åˆ’
    3. é€æ­¥æ‰§è¡Œ
    4. æ•´åˆç»“æœ
    """
    
    print("=" * 80)
    print(f"ğŸ¯ æ”¶åˆ°ä»»åŠ¡: {task}")
    print("=" * 80)
    
    # ========== é˜¶æ®µ1: åˆ¶å®šè®¡åˆ’ ==========
    print("\nğŸ“‹ é˜¶æ®µ1: åˆ¶å®šæ‰§è¡Œè®¡åˆ’\n")
    
    planning_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è§„åˆ’ä¸“å®¶ã€‚ç”¨æˆ·ç»™ä½ ä¸€ä¸ªä»»åŠ¡,ä½ éœ€è¦å°†å…¶åˆ†è§£æˆå¯æ‰§è¡Œçš„æ­¥éª¤ã€‚

å¯ç”¨å·¥å…·:
- web_search: æœç´¢äº’è”ç½‘ä¿¡æ¯
- calculate: æ•°å­¦è®¡ç®—

ä»»åŠ¡: {task}

è¯·åˆ†æè¿™ä¸ªä»»åŠ¡,ç„¶ååˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º:

{{
  "task_analysis": "ä»»åŠ¡åˆ†æ:è¿™ä¸ªä»»åŠ¡éœ€è¦...",
  "steps": [
    {{"step": 1, "action": "web_search", "query": "å…·ä½“æœç´¢å†…å®¹", "purpose": "ä¸ºä»€ä¹ˆè¦è¿™æ ·åš"}},
    {{"step": 2, "action": "web_search", "query": "...", "purpose": "..."}},
    ...
  ],
  "final_goal": "æœ€ç»ˆè¦è¾¾æˆä»€ä¹ˆç›®æ ‡"
}}

åªè¾“å‡ºJSON,ä¸è¦å…¶ä»–å†…å®¹ã€‚"""
    
    response = openai_client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": planning_prompt}],
        temperature=0.3
    )
    
    plan_text = response.choices[0].message.content
    
    # æå–JSON
    try:
        # ç§»é™¤å¯èƒ½çš„markdownæ ‡è®°
        plan_text = plan_text.replace('```json', '').replace('```', '').strip()
        plan = json.loads(plan_text)
    except:
        print("âŒ è®¡åˆ’è§£æå¤±è´¥,ä½¿ç”¨ç®€åŒ–æ¨¡å¼")
        return
    
    print(f"ğŸ“Š ä»»åŠ¡åˆ†æ:\n{plan['task_analysis']}\n")
    print(f"ğŸ¯ æœ€ç»ˆç›®æ ‡: {plan['final_goal']}\n")
    print(f"ğŸ“ æ‰§è¡Œè®¡åˆ’: å…± {len(plan['steps'])} ä¸ªæ­¥éª¤\n")
    
    for step in plan['steps']:
        print(f"  æ­¥éª¤{step['step']}: {step['action']}('{step['query'][:50]}...')")
        print(f"           ç›®çš„: {step['purpose']}\n")
    
    # ========== é˜¶æ®µ2: æ‰§è¡Œè®¡åˆ’ ==========
    print("\n" + "=" * 80)
    print("ğŸš€ é˜¶æ®µ2: æ‰§è¡Œè®¡åˆ’")
    print("=" * 80 + "\n")
    
    results = []
    
    for step_info in plan['steps']:
        step_num = step_info['step']
        action = step_info['action']
        query = step_info['query']
        
        print(f"ğŸ“ æ‰§è¡Œæ­¥éª¤ {step_num}/{len(plan['steps'])}")
        print(f"   åŠ¨ä½œ: {action}")
        print(f"   å‚æ•°: {query}")
        print(f"   ç›®çš„: {step_info['purpose']}\n")
        
        # æ‰§è¡Œå·¥å…·
        if action == "web_search":
            result = web_search(query)
        elif action == "calculate":
            result = calculate(query)
        else:
            result = f"æœªçŸ¥å·¥å…·: {action}"
        
        print(f"âœ… ç»“æœ:\n{result[:300]}...\n")
        print("-" * 80 + "\n")
        
        # ä¿å­˜ç»“æœ
        results.append({
            "step": step_num,
            "action": action,
            "query": query,
            "result": result
        })
    
    # ========== é˜¶æ®µ3: æ•´åˆç»“æœ ==========
    print("=" * 80)
    print("ğŸ“Š é˜¶æ®µ3: æ•´åˆæ‰€æœ‰ä¿¡æ¯")
    print("=" * 80 + "\n")
    
    # æ„å»ºæ•´åˆæç¤º
    synthesis_prompt = f"""ä½ åˆšåˆšæ‰§è¡Œäº†ä¸€ä¸ªå¤šæ­¥éª¤ä»»åŠ¡ã€‚ç°åœ¨éœ€è¦æ•´åˆæ‰€æœ‰ä¿¡æ¯,ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

åŸå§‹ä»»åŠ¡: {task}

æ‰§è¡Œçš„æ­¥éª¤å’Œç»“æœ:
"""
    
    for r in results:
        synthesis_prompt += f"\næ­¥éª¤{r['step']}: {r['action']}('{r['query']}')\n"
        synthesis_prompt += f"ç»“æœ: {r['result'][:500]}\n"
        synthesis_prompt += "-" * 40 + "\n"
    
    synthesis_prompt += f"""
è¯·æ ¹æ®ä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯,å®ŒæˆåŸå§‹ä»»åŠ¡: {task}

è¦æ±‚:
1. æ•´åˆæ‰€æœ‰æ­¥éª¤çš„ä¿¡æ¯
2. ç»™å‡ºæ¸…æ™°ã€å®Œæ•´çš„ç­”æ¡ˆ
3. ç”¨ç»“æ„åŒ–çš„æ–¹å¼å‘ˆç°(å¯ä»¥ç”¨æ ‡é¢˜ã€åˆ—è¡¨ç­‰)
4. å¦‚æœæŸäº›ä¿¡æ¯ä¸è¶³,è¯´æ˜éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶ä»€ä¹ˆ
"""
    
    print("ğŸ¤” AI æ­£åœ¨æ•´åˆä¿¡æ¯...\n")
    
    final_response = openai_client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": synthesis_prompt}],
        temperature=0.5
    )
    
    final_answer = final_response.choices[0].message.content
    
    print("=" * 80)
    print("âœ¨ æœ€ç»ˆç­”æ¡ˆ")
    print("=" * 80 + "\n")
    print(final_answer)
    print("\n" + "=" * 80)

# ========== æµ‹è¯•åœºæ™¯ ==========

if __name__ == "__main__":
    print("\nğŸ§  ä»»åŠ¡è§„åˆ’ Agent æ¼”ç¤º\n")
    
    # æµ‹è¯•1: ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡
    print("\n" + "ğŸ”·" * 40 + "\n")
    planning_agent("ä»‹ç»ä¸€ä¸‹ Rust ç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹å’Œä¸»è¦åº”ç”¨é¢†åŸŸ")
    
    print("\n\n" + "ğŸ”·" * 40 + "\n")
    
    # æµ‹è¯•2: æ›´å¤æ‚çš„ç ”ç©¶ä»»åŠ¡
    planning_agent("ç ”ç©¶2024å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»çš„èƒŒæ™¯å’Œä¸»è¦è´¡çŒ®,å¹¶è¯´æ˜è¿™é¡¹å·¥ä½œä¸ºä»€ä¹ˆé‡è¦")